# Wave-Transformer/CNN  

## models

msCNN and waveTransformer

## experiments

*[Configurations](experiments/ClonalAE/confs)

*[ClonalAE with waveTransformer](https://wandb.ai/genome_pretraining/WaveLSTM-ClonalAE/runs/1cn3jfmm?nw=nwusertonyu)

*[ClonalAE with waveCNN](https://wandb.ai/genome_pretraining/WaveLSTM-ClonalAE/runs/1gp03rlk?nw=nwusertonyu)

*[TCGA Classification with waveCNN](https://wandb.ai/genome_pretraining/WaveLSTM-clfTCGA/runs/19putmdc?nw=nwusertonyu)

## notebook

To visualize the attention maps and features from different resolutions: 
1. run experiments/ClonalAE/run_attentive_autoencoders.py to get saved outputs.
2. run experiments/ClonalAE/notebook/attention_notebook.ipynb.

## slides

https://docs.google.com/presentation/d/1_lMFyUzrKEEgvJS_wORm3tFPWSKnycfEBGduk6NW6hk/edit#slide=id.g220625a933e_0_0
